{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved -> pano_equirect_2048x1024.png\n",
      "saved -> pano_front_hemi_2048x1024.png\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fisheye_to_equirectangular_torch(\n",
    "    img_bgr_uint8,  # torch.uint8, [Hf, Wf, 3] 或 [Hf, Wf]\n",
    "    inv_poly_param,  # OCamCalib inv_polynomial 系数列表 (θ -> ρ)\n",
    "    affine_param,  # [c, d, e, xc, yc]\n",
    "    We=2048,\n",
    "    He=1024,  # 目标 equirectangular 分辨率，通常 He = We/2\n",
    "    yaw_range=(-math.pi, math.pi),  # 经度范围（水平）：默认全 360°\n",
    "    pitch_range=(-math.pi / 2, math.pi / 2),  # 纬度范围（垂直）：默认 -90°..+90°\n",
    "    padding_mode=\"zeros\",  # 超界填充：'zeros'|'border'|'reflection'\n",
    "):\n",
    "    \"\"\"\n",
    "    将单目鱼眼图（OCam 模型）重映射为 equirectangular 全景图。\n",
    "    返回: torch.uint8 的全景图 [He, We, 3] 或 [He, We]。\n",
    "    \"\"\"\n",
    "    # ---- 0) 输入张量 & 设备 ----\n",
    "    if img_bgr_uint8.dim() == 2:\n",
    "        Hf, Wf = img_bgr_uint8.shape\n",
    "        C = 1\n",
    "        img = img_bgr_uint8.unsqueeze(0).unsqueeze(0).float()  # [1,1,Hf,Wf]\n",
    "    else:\n",
    "        Hf, Wf, _ = img_bgr_uint8.shape\n",
    "        C = 3\n",
    "        img = img_bgr_uint8.permute(2, 0, 1).unsqueeze(0).float()  # [1,3,Hf,Wf]\n",
    "\n",
    "    device = img.device\n",
    "    dtype = img.dtype\n",
    "\n",
    "    # ---- 1) 为目标 equirect 生成经纬网格 (lon, lat) ----\n",
    "    # 水平 u -> 经度 lon ∈ [yaw_min, yaw_max]\n",
    "    # 垂直 v -> 纬度 lat ∈ [pitch_min, pitch_max]，注意 v 向下增大，因此要“从上往下”插值\n",
    "    yaw_min, yaw_max = float(yaw_range[0]), float(yaw_range[1])\n",
    "    pit_min, pit_max = float(pitch_range[0]), float(pitch_range[1])\n",
    "\n",
    "    u = torch.linspace(0, We - 1, We, device=device, dtype=dtype)\n",
    "    v = torch.linspace(0, He - 1, He, device=device, dtype=dtype)\n",
    "    uu, vv = torch.meshgrid(u, v, indexing=\"xy\")  # [He, We]\n",
    "\n",
    "    lon = yaw_min + uu * (yaw_max - yaw_min) / max(We - 1, 1)  # [-π, π]\n",
    "    lat = pit_max - vv * (pit_max - pit_min) / max(He - 1, 1)  # [+π/2 .. -π/2] 从上到下\n",
    "\n",
    "    # ---- 2) 经纬 -> 摄像机坐标系下的单位方向 (x,y,z) ----\n",
    "    # 约定：相机坐标 z 前方、x 右、y 下（与像素 v 同向）\n",
    "    # 用这样的定义：前方 (lon=0, lat=0) -> (0,0,1)\n",
    "    # 顶部 (lat=+90°)        -> (0,-1,0)\n",
    "    # 右侧 (lon=+90°, lat=0) -> (1,0,0)\n",
    "    cos_lat = torch.cos(lat)\n",
    "    sin_lat = torch.sin(lat)\n",
    "    sin_lon = torch.sin(lon)\n",
    "    cos_lon = torch.cos(lon)\n",
    "\n",
    "    dx = cos_lat * sin_lon\n",
    "    dy = -sin_lat  # 注意负号：lat 向上为正，而像素 y 向下为正\n",
    "    dz = cos_lat * cos_lon\n",
    "\n",
    "    # ---- 3) OCamCalib 投影：方向 -> 鱼眼像素 (u_f, v_f) ----\n",
    "    eps = 1e-6\n",
    "    M = torch.sqrt(dx * dx + dy * dy)\n",
    "    M_safe = torch.clamp(M, min=eps)\n",
    "    theta = -torch.atan2(\n",
    "        dz, M_safe\n",
    "    )  # 与你给的函数一致：theta = -atan2(z, sqrt(x^2+y^2))\n",
    "\n",
    "    # ρ(θ) 用 Horner 法稳定计算\n",
    "    inv_poly = torch.tensor(inv_poly_param, dtype=dtype, device=device)\n",
    "    rho = torch.zeros_like(theta)\n",
    "    for a in reversed(inv_poly):\n",
    "        rho = rho * theta + a\n",
    "\n",
    "    # 单位化平面方向 * ρ\n",
    "    x_dir = dx / M_safe * rho\n",
    "    y_dir = dy / M_safe * rho\n",
    "\n",
    "    # 仿射 + 主点\n",
    "    c, d, e, xc, yc = [float(t) for t in affine_param]\n",
    "    u_f = c * x_dir + d * y_dir + xc\n",
    "    v_f = e * x_dir + y_dir + yc\n",
    "\n",
    "    # ---- 4) grid_sample 采样需要把 (u_f, v_f) 归一化到 [-1,1] ----\n",
    "    grid_x = (u_f / (Wf - 1)) * 2.0 - 1.0\n",
    "    grid_y = (v_f / (Hf - 1)) * 2.0 - 1.0\n",
    "    grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0)  # [1,He,We,2]\n",
    "\n",
    "    # ---- 5) 从鱼眼图采样得到全景 ----\n",
    "    pano = F.grid_sample(\n",
    "        img, grid, mode=\"bilinear\", padding_mode=padding_mode, align_corners=True\n",
    "    )  # [1,C,He,We]\n",
    "\n",
    "    # ---- 6) 输出 uint8 HxWxC ----\n",
    "    pano = torch.clamp(pano, 0, 255).round().byte()\n",
    "    if C == 1:\n",
    "        return pano.squeeze(0).squeeze(0)  # [He, We]\n",
    "    else:\n",
    "        return pano.squeeze(0).permute(1, 2, 0)  # [He, We, 3]\n",
    "\n",
    "\n",
    "# ---------------- 使用示例 ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    import cv2\n",
    "\n",
    "    inv_poly_param = [\n",
    "        889.91582358,\n",
    "        528.72413142,\n",
    "        -20.52846684,\n",
    "        67.73730056,\n",
    "        48.02888563,\n",
    "        -14.14051173,\n",
    "        20.22746961,\n",
    "        38.15325087,\n",
    "        -6.98641569,\n",
    "        -26.68100659,\n",
    "        -12.41222046,\n",
    "        -1.83261524,\n",
    "    ]\n",
    "    affine_param = [\n",
    "        9.99949231e-01,\n",
    "        -4.44517298e-04,\n",
    "        6.30993143e-04,\n",
    "        9.68732891e02,\n",
    "        7.48514758e02,\n",
    "    ]\n",
    "\n",
    "    # 读入你的 1920x1536 鱼眼图（BGR）\n",
    "    fisheye = cv2.imread(\"./assets/SurCam01.jpeg\", cv2.IMREAD_COLOR)\n",
    "    assert fisheye is not None and fisheye.shape[1] == 1920 and fisheye.shape[0] == 1536\n",
    "\n",
    "    # -> torch\n",
    "    img_t = torch.from_numpy(fisheye)  # [Hf,Wf,3], uint8\n",
    "\n",
    "    # 生成 360x180 的 equirect（注意：背面会是黑的，因为单目看不到）\n",
    "    pano = (\n",
    "        fisheye_to_equirectangular_torch(\n",
    "            img_t,\n",
    "            inv_poly_param,\n",
    "            affine_param,\n",
    "            We=2048,\n",
    "            He=1024,  # 典型比例：He = We/2\n",
    "            yaw_range=(-math.pi, math.pi),  # 全 360°\n",
    "            pitch_range=(-math.pi / 2, math.pi / 2),  # -90°..+90°\n",
    "            padding_mode=\"zeros\",\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    cv2.imwrite(\"pano_equirect_2048x1024.png\", pano)\n",
    "    print(\"saved -> pano_equirect_2048x1024.png\")\n",
    "\n",
    "    # 如果你只想要前半球（避免黑边），把 yaw 限制到 180°：\n",
    "    pano_front = (\n",
    "        fisheye_to_equirectangular_torch(\n",
    "            img_t,\n",
    "            inv_poly_param,\n",
    "            affine_param,\n",
    "            We=2048,\n",
    "            He=1024,\n",
    "            yaw_range=(-math.pi / 2, math.pi / 2),  # 只取 -90°..+90° 水平\n",
    "            pitch_range=(-math.pi / 2, math.pi / 2),  # 垂直仍是 -90°..+90°\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    cv2.imwrite(\"pano_front_hemi_2048x1024.png\", pano_front)\n",
    "    print(\"saved -> pano_front_hemi_2048x1024.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved -> equisolid_1920x1920_FOV200.0.png\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def fisheye_to_equisolid_torch(\n",
    "    img_bgr_uint8,      # torch.uint8 [Hf, Wf, 3] 或 [Hf, Wf]\n",
    "    inv_poly_param,     # list/np.array, len = N (你的 OCamCalib inverse polynomial)\n",
    "    affine_param,       # [c, d, e, xc, yc]\n",
    "    W_out=1920,         # 输出等立体角图宽\n",
    "    H_out=1920,         # 输出等立体角图高（建议方形以容纳完整圆盘）\n",
    "    FOV_deg=180.0,      # 体视投影的视场（圆盘直径），边缘对应 FOV/2\n",
    "):\n",
    "    \"\"\"\n",
    "    将单张鱼眼图（OCamCalib 模型）重映射为等立体角(体视)投影平面图。\n",
    "    返回 torch.uint8 的图，形状 [H_out, W_out, 3] 或 [H_out, W_out]。\n",
    "    \"\"\"\n",
    "    # ---- 1) 准备输入图像张量 ----\n",
    "    if img_bgr_uint8.dim() == 2:\n",
    "        Hf, Wf = img_bgr_uint8.shape\n",
    "        C = 1\n",
    "        img = img_bgr_uint8.unsqueeze(0).unsqueeze(0).float()  # [1,1,Hf,Wf]\n",
    "    else:\n",
    "        Hf, Wf, _ = img_bgr_uint8.shape\n",
    "        C = 3\n",
    "        img = img_bgr_uint8.permute(2, 0, 1).unsqueeze(0).float()  # [1,3,Hf,Wf]\n",
    "\n",
    "    device = img.device\n",
    "\n",
    "    # ---- 2) 输出平面中心与等效焦距 f（等立体角）----\n",
    "    cx = W_out / 2.0\n",
    "    cy = H_out / 2.0\n",
    "    r_edge = min(cx, cy)  # 圆盘的边界半径（像素）\n",
    "    # FOV 定义为圆盘直径覆盖的视场 => 边缘对应 θ_edge = FOV/2\n",
    "    theta_edge = math.radians(FOV_deg / 2.0)\n",
    "    # 等立体角: r = 2 f sin(θ/2) => f = r_edge / (2 sin(θ_edge/2))\n",
    "    f_eq = r_edge / (2.0 * math.sin(theta_edge / 2.0))\n",
    "\n",
    "    # ---- 3) 生成输出平面像素网格 (u,v) 并换算到以中心为原点的坐标 ----\n",
    "    u = torch.linspace(0, W_out - 1, W_out, device=device)\n",
    "    v = torch.linspace(0, H_out - 1, H_out, device=device)\n",
    "    uu, vv = torch.meshgrid(u, v, indexing=\"xy\")  # [H_out, W_out]\n",
    "\n",
    "    dx = uu - cx\n",
    "    dy = vv - cy\n",
    "    r = torch.sqrt(dx * dx + dy * dy)  # 到中心的半径\n",
    "\n",
    "    # 方位角 φ\n",
    "    phi = torch.atan2(dy, dx)  # [-pi, pi]\n",
    "\n",
    "    # ---- 4) 半径->极角：r = 2 f sin(θ/2) => θ = 2 * asin(r/(2f))，圆外设为无效（黑色）----\n",
    "    # 为了数值安全，先 clamp\n",
    "    denom = 2.0 * f_eq\n",
    "    r_norm = torch.clamp(r / denom, min=0.0, max=1.0)  # >1 的在圆外，稍后黑边\n",
    "    theta = 2.0 * torch.asin(r_norm)  # [0, π]，当 r==r_edge 且 FOV=180° => θ=90°\n",
    "\n",
    "    # ---- 5) 构造单位方向向量 [x,y,z]（以光轴为 z）----\n",
    "    sin_theta = torch.sin(theta)\n",
    "    cos_theta = torch.cos(theta)\n",
    "    x_dir = sin_theta * torch.cos(phi)\n",
    "    y_dir = sin_theta * torch.sin(phi)\n",
    "    z_dir = cos_theta\n",
    "\n",
    "    # ---- 6) 用与你原函数一致的 OCamCalib 角度定义求 rho(θ_ocam) ----\n",
    "    # 原代码：M = sqrt(x^2 + y^2)，theta_ocam = -atan2(z, M)\n",
    "    M = torch.sqrt(x_dir * x_dir + y_dir * y_dir)\n",
    "    eps = 1e-6\n",
    "    M_safe = torch.clamp(M, min=eps)\n",
    "    theta_ocam = -torch.atan2(z_dir, M_safe)\n",
    "\n",
    "    inv_poly = torch.tensor(inv_poly_param, dtype=x_dir.dtype, device=device)  # [N]\n",
    "    # Horner 法：\n",
    "    rho = torch.zeros_like(theta_ocam)\n",
    "    for a in reversed(inv_poly):\n",
    "        rho = rho * theta_ocam + a\n",
    "\n",
    "    # ---- 7) 仿射映射到鱼眼像素 (u_f, v_f) ----\n",
    "    c, d, e, xc, yc = [float(t) for t in affine_param]\n",
    "\n",
    "    # 与原实现一致：将平面方向单位化后乘 rho\n",
    "    scale = rho / M_safe  # ~= rho * (1 / sqrt(x^2+y^2))\n",
    "    x_img = x_dir * scale\n",
    "    y_img = y_dir * scale\n",
    "\n",
    "    u_f = c * x_img + d * y_img + xc\n",
    "    v_f = e * x_img +       y_img + yc\n",
    "\n",
    "    # ---- 8) 归一化到 [-1,1] 并 grid_sample 采样 ----\n",
    "    grid_x = (u_f / (Wf - 1)) * 2.0 - 1.0\n",
    "    grid_y = (v_f / (Hf - 1)) * 2.0 - 1.0\n",
    "    grid = torch.stack([grid_x, grid_y], dim=-1).unsqueeze(0)  # [1,H_out,W_out,2]\n",
    "\n",
    "    # 圆外区域（r > r_edge 或 r_norm>1）我们直接标成越界值，使其变黑：\n",
    "    # 最简单方式：保持 grid 值在 [-2, -2]（明显越界），从而 padding_mode=\"zeros\" 给黑色。\n",
    "    outside_mask = (r > r_edge + 1e-6)\n",
    "    if outside_mask.any():\n",
    "        mask4 = outside_mask.unsqueeze(0).unsqueeze(-1)  # [1,H_out,W_out,1]\n",
    "        grid = torch.where(mask4, torch.full_like(grid, -2.0), grid)\n",
    "\n",
    "    out_img = F.grid_sample(\n",
    "        img, grid, mode=\"bilinear\", padding_mode=\"zeros\", align_corners=True\n",
    "    )  # [1,C,H_out,W_out]\n",
    "\n",
    "    # ---- 9) 输出为 uint8 HxWxC ----\n",
    "    out_img = torch.clamp(out_img, 0, 255).round().byte()\n",
    "    if C == 1:\n",
    "        out = out_img.squeeze(0).squeeze(0)  # [H_out, W_out]\n",
    "    else:\n",
    "        out = out_img.squeeze(0).permute(1, 2, 0)  # [H_out, W_out, 3]\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------- 使用示例 ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    inv_poly_param = [\n",
    "        889.91582358, 528.72413142, -20.52846684, 67.73730056,\n",
    "        48.02888563, -14.14051173, 20.22746961, 38.15325087,\n",
    "        -6.98641569, -26.68100659, -12.41222046, -1.83261524,\n",
    "    ]\n",
    "    affine_param = [\n",
    "        9.99949231e-01, -4.44517298e-04, 6.30993143e-04, 9.68732891e02, 7.48514758e02,\n",
    "    ]\n",
    "\n",
    "    # 读取 1920x1536 的鱼眼图 (BGR)\n",
    "    fisheye = cv2.imread(\"./assets/SurCam01.jpeg\", cv2.IMREAD_COLOR)\n",
    "    assert fisheye is not None and fisheye.shape[1] == 1920 and fisheye.shape[0] == 1536\n",
    "\n",
    "    img_t = torch.from_numpy(fisheye)  # [H,W,3], uint8, BGR\n",
    "\n",
    "    # 输出等立体角图：建议方形画布容纳完整 180° 圆盘\n",
    "    W_out, H_out, FOV = 1920, 1920, 200.0\n",
    "    equisolid_bgr = (\n",
    "        fisheye_to_equisolid_torch(\n",
    "            img_t, inv_poly_param, affine_param,\n",
    "            W_out=W_out, H_out=H_out, FOV_deg=FOV\n",
    "        )\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    cv2.imwrite(f\"equisolid_{W_out}x{H_out}_FOV{FOV}.png\", equisolid_bgr)\n",
    "    print(f\"saved -> equisolid_{W_out}x{H_out}_FOV{FOV}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
